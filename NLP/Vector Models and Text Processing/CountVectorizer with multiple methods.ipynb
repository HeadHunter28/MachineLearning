{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b480c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wget\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#MultinomialNB is the classifier for this choice.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3ca33",
   "metadata": {},
   "source": [
    "To download file : (had to download manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification\n",
    "#wget.download('https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de202c",
   "metadata": {},
   "source": [
    "Reading csv file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef497def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Asus\\Desktop\\All Code\\NLP\\Vector Models and Text Processing\\bbc_text_cls.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d6ea0",
   "metadata": {},
   "source": [
    "Checking file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cae28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdadf2",
   "metadata": {},
   "source": [
    "Assigning the input data and target data to variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e88f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df['text']\n",
    "labels = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.hist(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04818afd",
   "metadata": {},
   "source": [
    "The above histogram plot shows that the documents are fairly evenly spread out over all the labels.\n",
    "The data is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb663f3",
   "metadata": {},
   "source": [
    "To split training and testing data from given dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, output_train, output_test =train_test_split(inputs,labels,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356d538",
   "metadata": {},
   "source": [
    "Instantiate vectorizer and TRAIN/FIT on training data as well as testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59314ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "\n",
    "Xtrain=vectorizer.fit_transform(input_train)\n",
    "Xtest=vectorizer.transform(input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9861d2",
   "metadata": {},
   "source": [
    "Xtrain/Xtest are both vectorizers, i.e. they are in form of a sparse matrix, consisiting of values of each document\n",
    "represented as a vector.\n",
    "\n",
    "Number of rows = Number of documents\n",
    "Number of columns = Number of vocabulary size\n",
    "\n",
    "Number of 0s = Number of words absent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5585c3c",
   "metadata": {},
   "source": [
    "To check how sparse the matrix is, how many values are non zero, we will do :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc16657",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d580b",
   "metadata": {},
   "source": [
    "To check overall percentage of values which are non zero : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain != 0).sum() / np.prod((Xtrain.shape)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b9924",
   "metadata": {},
   "source": [
    "Since less than 1% of matrix contains non zero values, it is justified to employ a sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96a513",
   "metadata": {},
   "source": [
    "Instantiating a classifer of Naive Bayes class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a64679",
   "metadata": {},
   "source": [
    "Fitting the model on train and testing set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45415b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain,output_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d0054",
   "metadata": {},
   "source": [
    "Checking score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training score :\",model.score(Xtrain,output_train))\n",
    "print(\"Testing score :\",model.score(Xtest,output_test))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9427d",
   "metadata": {},
   "source": [
    "Now, by implementing the identification and removal of stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b449dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1=CountVectorizer(stop_words='english')\n",
    "Xtrain=vectorizer.fit_transform(input_train)\n",
    "Xtest=vectorizer.transform(input_test)\n",
    "model1=MultinomialNB()\n",
    "model1.fit(Xtrain,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score for model\",model1.score(Xtrain,output_train))\n",
    "print(\"Test score for model\",model1.score(Xtest,output_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c80b6",
   "metadata": {},
   "source": [
    "The results are similar to previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba695d3e",
   "metadata": {},
   "source": [
    "Now we will implement Lemmatization with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560a89c",
   "metadata": {},
   "source": [
    "Function to map parts of speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b00edad",
   "metadata": {},
   "source": [
    "The class LemmaTokeniser, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokeniser:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self,doc):\n",
    "        tokens=word_tokenize(doc)\n",
    "        words_and_tags= nltk.pos_tag(tokens)\n",
    "        return [self.wnl.lemmatize(word,pos= get_wordnet_pos(tag)) for word,tag in words_and_tags ]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278af68",
   "metadata": {},
   "source": [
    "implementing lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2= CountVectorizer(tokenizer=LemmaTokeniser())\n",
    "Xtrain=vectorizer2.fit_transform(input_train)\n",
    "Xtest=vectorizer2.transform(input_test)\n",
    "model3=MultinomialNB()\n",
    "model3.fit(Xtrain,output_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score with lemmatisation:\",model.score(Xtrain,output_train))\n",
    "print(\"Test score with lemmatisation:\",model.score(Xtest,output_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28328bf9",
   "metadata": {},
   "source": [
    "Next, we will implement stemming for tokenising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedefa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.porter= PorterStemmer()\n",
    "    def __call__(self,doc):\n",
    "        tokens=word_tokenize(doc)\n",
    "        return [self.porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1=CountVectorizer(tokenizer=StemTokenizer())\n",
    "Xtrain=vectorizer.fit_transform(input_train)\n",
    "Xtest=vectorizer.transform(input_test)\n",
    "model3=MultinomialNB()\n",
    "model3.fit(Xtrain,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34001f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score for model\",model3.score(Xtrain,output_train))\n",
    "print(\"Test score for model\",model3.score(Xtest,output_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef924bfb",
   "metadata": {},
   "source": [
    "Now, implementing simple string split for tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1=CountVectorizer(tokenizer=simple_tokenizer)\n",
    "Xtrain=vectorizer.fit_transform(input_train)\n",
    "Xtest=vectorizer.transform(input_test)\n",
    "model4=MultinomialNB()\n",
    "model4.fit(Xtrain,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score for model\",model4.score(Xtrain,output_train))\n",
    "print(\"Test score for model\",model4.score(Xtest,output_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285cd89",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
