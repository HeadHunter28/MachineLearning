{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bd0f8f",
   "metadata": {},
   "source": [
    "The objective is to build a recommender system for movies.\n",
    "\n",
    "A dataset containing titles, genres, keywords,synopsis etc. will be downloaded.\n",
    "https://www.kaggle.com/tmdb/tmdb-movie-metadata\n",
    "\n",
    "\n",
    "A query will have the title of a movie, which must be existing in the dataset, and top 5 recommendations must be provided based on the given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d424d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d3631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://lazyprogrammer.me/course_files/nlp/tmdb_5000_movies.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec17ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata=pd.read_csv('tmdb_5000_movies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c16a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviedata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399a70a",
   "metadata": {},
   "source": [
    "It is observed that some of the columns store values as json strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fb1ae",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Checking the first row of data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1=moviedata.iloc[0]\n",
    "row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a20c61",
   "metadata": {},
   "source": [
    "This is a list of json strings, and the useful attribute here is \"name\", which contains the names of the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1['keywords']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f7fee",
   "metadata": {},
   "source": [
    "Even in this case, the only attribute required is \"name\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b254463",
   "metadata": {},
   "source": [
    "We need to convert this json string to a usable format.\n",
    "json.loads() method can be used to parse a valid JSON string and\n",
    "convert it into a Python Dictionary, as implemented here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=json.loads(row1['genres'])\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ff3d6",
   "metadata": {},
   "source": [
    "We need to convert this dictionary/json to a single string of text, such that it is appropriate for TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(\"\".join(x[\"name\"].split()) for x in x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b01148",
   "metadata": {},
   "source": [
    "Taking the \"name\" key of every entry, split it on whitespace, \n",
    "and join it back together using empty string '' (for cases like Science Fiction made to ScienceFiction)\n",
    "\n",
    "This will be done for all genre \"name\" elements, which are then joined by the final outer join() function, \n",
    "concatenating all genre tokens with a single whitespace between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3f13",
   "metadata": {},
   "source": [
    "We need to implement this for all genres and keywords of all rows over the entire dataset, \n",
    "implemented by :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b209fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genres_and_keywords_to_string(row):\n",
    "    genres=json.loads(row['genres'])\n",
    "    genres= \" \".join(\"\".join(x[\"name\"].split()) for x in genres)\n",
    "    \n",
    "    keywords=json.loads(row['keywords'])\n",
    "    keywords=\" \".join(\"\".join(y[\"name\"].split()) for y in keywords)\n",
    "    \n",
    "    combinedstring=\"%s %s\" %(genres,keywords)\n",
    "    \n",
    "    return combinedstring\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13738b86",
   "metadata": {},
   "source": [
    "This function converts the useful tokens from each json row's genres and keywords to a single string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e8caa",
   "metadata": {},
   "source": [
    "*It must be clear at this point that we are considering only the genres and keywords data to compare between the movies \n",
    "in the scope of this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we can apply this function to each row, and generate a new column named string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b4bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviedata['string']=moviedata.apply(genres_and_keywords_to_string,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e488720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we will create an instance of the TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ed045",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvectorizer=TfidfVectorizer(max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e870be",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1= tfvectorizer.fit_transform(moviedata['string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42cccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc18ffb",
   "metadata": {},
   "source": [
    "When we recieve a query, to correspond between the vectorizer matrix, and the original dataframe, we will use the index,\n",
    "as both are ordered in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53820827",
   "metadata": {},
   "outputs": [],
   "source": [
    "So, we need to generate a MAPPING FOR each movie title to its index in the dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2idx=pd.Series(moviedata.index,index=moviedata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe140b49",
   "metadata": {},
   "source": [
    "And now, a function to get the index of a movie from its title :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612eeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(name):\n",
    "    return movie2idx[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec40c9",
   "metadata": {},
   "source": [
    "Now, for example, we can get the index of the movie Scream 3 from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=find_index('Scream 3')\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cabebcc",
   "metadata": {},
   "source": [
    "And use that index to lookup the corresponding TFIDF vector for Scream 3 in the vectorizer's matrix (M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cae1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=M1[j]\n",
    "query.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef0452",
   "metadata": {},
   "source": [
    "So, we have established a link between the vectorizer's matrix and the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fe644",
   "metadata": {},
   "source": [
    "Now, assuming we have to obtained user's query, we have to find its similarity to the other movies in order to recommend\n",
    "similar ones \n",
    "i.e. we have to compute the similarity of the given movie's vector to the all the other movie vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f97b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cosine_similarity(query,M1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c16ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "The array storing the result of similarity scores is of dimension 1xN, so we have to make it a 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13254570",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97232f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d9dab",
   "metadata": {},
   "source": [
    "Now, we need the most similar scores, that is the largest values of similarity scores.\n",
    "So we need to sort to sort them in descending order, \n",
    "\n",
    " To make things simpler, can use argsort() function, which orders a given set of elements, but reports the result indirectly usingthe existing manner of indexes.\n",
    "\n",
    "In this case, it will return the dataframe index of the movies in descending order of the movies's similarity scores.\n",
    "\n",
    "(-scores) is used to get the elements such that argsort(), which sorts in ascending order, will actually sort the scores in \n",
    "descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores =(-scores).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((-scores).argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a11b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we have obtained the scores in descending order, we need to extract the top 5 scores of the movies.\n",
    "We have to ignore the first value, since the query movie will have the highest similairty score for itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_indices= result_scores[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77596a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "And now to extract the corresponding movie titles for the indexes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recd_movies=moviedata['title'].iloc[result_indices]\n",
    "recd_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1c3b0",
   "metadata": {},
   "source": [
    "Thus, from a query, we have obtained the 5 most similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "To implement the entire process as a function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movie):\n",
    "    idX=find_index(movie)\n",
    "    if type(idX) == pd.Series:\n",
    "        idX=idX.iloc[0]\n",
    "    result= (-(cosine_similarity(M1[idX],M1).flatten())).argsort()[1:6]\n",
    "    print(moviedata['title'].iloc[result])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d23f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('Fury')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "580c8ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: nbconvert[qtpdf] in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (7.2.8)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (4.11.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (5.0.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (2.1.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (0.7.2)\n",
      "Requirement already satisfied: nbformat>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (5.7.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (22.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (2.14.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert[qtpdf]) (5.8.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core>=4.7->nbconvert[qtpdf]) (2.6.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core>=4.7->nbconvert[qtpdf]) (305)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbclient>=0.5.0->nbconvert[qtpdf]) (7.4.9)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.1->nbconvert[qtpdf]) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.1->nbconvert[qtpdf]) (4.17.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert[qtpdf]) (2.3.2.post1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach->nbconvert[qtpdf]) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach->nbconvert[qtpdf]) (0.5.1)\n",
      "Collecting pyqtwebengine>=5.15\n",
      "  Downloading PyQtWebEngine-5.15.6-cp37-abi3-win_amd64.whl (182 kB)\n",
      "     ------------------------------------- 182.7/182.7 kB 74.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert[qtpdf]) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert[qtpdf]) (0.19.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (1.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (25.0.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (6.2)\n",
      "Collecting PyQt5-sip<13,>=12.11\n",
      "  Downloading PyQt5_sip-12.12.2-cp311-cp311-win_amd64.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB ? eta 0:00:00\n",
      "Collecting PyQtWebEngine-Qt5>=5.15.0\n",
      "  Downloading PyQtWebEngine_Qt5-5.15.2-py3-none-win_amd64.whl (60.0 MB)\n",
      "     --------------------------------------- 60.0/60.0 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting PyQt5>=5.15.4\n",
      "  Downloading PyQt5-5.15.9-cp37-abi3-win_amd64.whl (6.8 MB)\n",
      "     ---------------------------------------- 6.8/6.8 MB 24.3 MB/s eta 0:00:00\n",
      "Collecting PyQt5-Qt5>=5.15.2\n",
      "  Using cached PyQt5_Qt5-5.15.2-py3-none-win_amd64.whl (50.1 MB)\n",
      "Installing collected packages: PyQtWebEngine-Qt5, PyQt5-Qt5, PyQt5-sip, PyQt5, pyqtwebengine\n",
      "Successfully installed PyQt5-5.15.9 PyQt5-Qt5-5.15.2 PyQt5-sip-12.12.2 PyQtWebEngine-Qt5-5.15.2 pyqtwebengine-5.15.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert[qtpdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669b611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
